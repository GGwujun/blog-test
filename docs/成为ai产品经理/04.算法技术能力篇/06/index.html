<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-test/umi.css" />
    <script>
      window.routerBase = "/blog-test";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>13 | 决策树与随机森林：如何预测用户会不会违约？ - 大师兄</title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/成为ai产品经理/04.算法技术能力篇/06" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-test/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>计算机基础</span><span>算法</span><span>前端开发<ul><li><a href="/blog-test/新时代产品经理进阶之路">新时代产品经理进阶之路</a></li></ul></span><span>前端工程化</span><span>前端性能优化</span><span>移动端开发</span><span>软件测试<ul><li><a href="/blog-test/全链路压测实战30讲">全链路压测实战30讲</a></li><li><a href="/blog-test/性能测试实战30讲">性能测试实战30讲</a></li><li><a href="/blog-test/接口测试入门课">接口测试入门课</a></li><li><a href="/blog-test/程序员的测试课">程序员的测试课</a></li><li><a href="/blog-test/自动化测试高手课">自动化测试高手课</a></li><li><a href="/blog-test/软件测试52讲">软件测试52讲</a></li></ul></span><span>产品与用户体验<ul><li><a aria-current="page" class="active" href="/blog-test/成为ai产品经理">成为ai产品经理</a></li><li><a href="/blog-test/硅谷产品实战36讲">硅谷产品实战36讲</a></li><li><a href="/blog-test/苏杰的产品创新课">苏杰的产品创新课</a></li></ul></span><span>面试</span><span>杂谈<ul><li><a href="/blog-test/b测试从0到1">b测试从0到1</a></li><li><a href="/blog-test/tob市场品牌实战课">tob市场品牌实战课</a></li><li><a href="/blog-test/从0开始做增长">从0开始做增长</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-test/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>计算机基础</li><li>算法</li><li>前端开发<ul><li><a href="/blog-test/新时代产品经理进阶之路">新时代产品经理进阶之路</a></li></ul></li><li>前端工程化</li><li>前端性能优化</li><li>移动端开发</li><li>软件测试<ul><li><a href="/blog-test/全链路压测实战30讲">全链路压测实战30讲</a></li><li><a href="/blog-test/性能测试实战30讲">性能测试实战30讲</a></li><li><a href="/blog-test/接口测试入门课">接口测试入门课</a></li><li><a href="/blog-test/程序员的测试课">程序员的测试课</a></li><li><a href="/blog-test/自动化测试高手课">自动化测试高手课</a></li><li><a href="/blog-test/软件测试52讲">软件测试52讲</a></li></ul></li><li>产品与用户体验<ul><li><a aria-current="page" class="active" href="/blog-test/成为ai产品经理">成为ai产品经理</a></li><li><a href="/blog-test/硅谷产品实战36讲">硅谷产品实战36讲</a></li><li><a href="/blog-test/苏杰的产品创新课">苏杰的产品创新课</a></li></ul></li><li>面试</li><li>杂谈<ul><li><a href="/blog-test/b测试从0到1">b测试从0到1</a></li><li><a href="/blog-test/tob市场品牌实战课">tob市场品牌实战课</a></li><li><a href="/blog-test/从0开始做增长">从0开始做增长</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-test/成为ai产品经理">成为ai产品经理</a></li><li><a href="/blog-test/成为ai产品经理/01.开篇词">01.开篇词</a><ul><li><a href="/blog-test/成为ai产品经理/01.开篇词/01"><span>开篇词 | 你好，产品经理！你的未来价值壁垒在哪儿？</span></a></li></ul></li><li><a href="/blog-test/成为ai产品经理/02.知己知彼ai和ai产品经理">02.知己知彼AI和AI产品经理</a><ul><li><a href="/blog-test/成为ai产品经理/02.知己知彼ai和ai产品经理/01"><span>01 | 行业视角：产品经理眼中的人工智能</span></a></li><li><a href="/blog-test/成为ai产品经理/02.知己知彼ai和ai产品经理/02"><span>02 | 个人视角：成为AI产品经理，要先搞定这两个问题</span></a></li><li><a href="/blog-test/成为ai产品经理/02.知己知彼ai和ai产品经理/03"><span>03 | 技术视角：AI产品经理需要懂的技术全景图</span></a></li><li><a href="/blog-test/成为ai产品经理/02.知己知彼ai和ai产品经理/04"><span>04 | 过来人讲：成为AI产品经理的两条路径</span></a></li></ul></li><li><a href="/blog-test/成为ai产品经理/03.项目管控能力篇">03.项目管控能力篇</a><ul><li><a href="/blog-test/成为ai产品经理/03.项目管控能力篇/01"><span>05 | 通过一个 AI 产品的落地，掌握产品经理工作全流程</span></a></li><li><a href="/blog-test/成为ai产品经理/03.项目管控能力篇/02"><span>06 | AI 模型的构建过程是怎样的？（上）</span></a></li><li><a href="/blog-test/成为ai产品经理/03.项目管控能力篇/03"><span>07 | AI模型的构建过程是怎样的（下）</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-test/成为ai产品经理/04.算法技术能力篇">04.算法技术能力篇</a><ul><li><a href="/blog-test/成为ai产品经理/04.算法技术能力篇/01"><span>08 | 算法全景图：AI产品经理必须要懂的算法有哪些？</span></a></li><li><a href="/blog-test/成为ai产品经理/04.算法技术能力篇/02"><span>09 | K近邻算法：机器学习入门必学算法</span></a></li><li><a href="/blog-test/成为ai产品经理/04.算法技术能力篇/03"><span>10 | 线性回归：教你预测，投放多少广告带来的收益最大</span></a></li><li><a href="/blog-test/成为ai产品经理/04.算法技术能力篇/04"><span>11 | 逻辑回归：如何预测用户是否会购买商品？</span></a></li><li><a href="/blog-test/成为ai产品经理/04.算法技术能力篇/05"><span>12 | 朴素贝叶斯：让AI告诉你，航班延误险该不该买？</span></a></li><li><a aria-current="page" class="active" href="/blog-test/成为ai产品经理/04.算法技术能力篇/06"><span>13 | 决策树与随机森林：如何预测用户会不会违约？</span></a></li><li><a href="/blog-test/成为ai产品经理/04.算法技术能力篇/07"><span>14 | 支持向量机：怎么预测股票市场的涨与跌？</span></a></li><li><a href="/blog-test/成为ai产品经理/04.算法技术能力篇/08"><span>15 | K-means 聚类算法：如何挖掘高价值用户？</span></a></li><li><a href="/blog-test/成为ai产品经理/04.算法技术能力篇/09"><span>期中答疑 | AI产品经理热门问题答疑合集</span></a></li><li><a href="/blog-test/成为ai产品经理/04.算法技术能力篇/10"><span>期中周测试题 ，你做对了吗？</span></a></li><li><a href="/blog-test/成为ai产品经理/04.算法技术能力篇/11"><span>16 | 深度学习：当今最火的机器学习技术，你一定要知道</span></a></li></ul></li><li><a href="/blog-test/成为ai产品经理/05.模型评估能力篇">05.模型评估能力篇</a><ul><li><a href="/blog-test/成为ai产品经理/05.模型评估能力篇/01"><span>17 | 模型评估：从一个失控的项目看优秀的产品经理如何评估AI模型？</span></a></li><li><a href="/blog-test/成为ai产品经理/05.模型评估能力篇/02"><span>18 | 核心技能：产品经理评估模型需要关注哪些指标？</span></a></li><li><a href="/blog-test/成为ai产品经理/05.模型评估能力篇/03"><span>19 | 模型性能评估（一）：从信用评分产品看什么是混淆矩阵？</span></a></li><li><a href="/blog-test/成为ai产品经理/05.模型评估能力篇/04"><span>20 | 模型性能评估（二）：从信用评分产品看什么是KS、AUC？</span></a></li><li><a href="/blog-test/成为ai产品经理/05.模型评估能力篇/05"><span>21 | 模型性能评估（三）：从股价预测产品看回归算法常用的评估指标</span></a></li><li><a href="/blog-test/成为ai产品经理/05.模型评估能力篇/06"><span>22 | 模型稳定性评估：如何用PSI来评估信用评分产品的稳定性？</span></a></li><li><a href="/blog-test/成为ai产品经理/05.模型评估能力篇/07"><span>春节加餐1 | 用户增长模型：怎么利用AI技术判断新渠道性价比？</span></a></li><li><a href="/blog-test/成为ai产品经理/05.模型评估能力篇/08"><span>春节加餐2 | 一次答疑，带你回顾模型评估的所有基础概念</span></a></li><li><a href="/blog-test/成为ai产品经理/05.模型评估能力篇/09"><span>23 | 模型监控：产品经理如何建设算法模型监控指标体系？</span></a></li></ul></li><li><a href="/blog-test/成为ai产品经理/06.ai项目实践篇">06.AI项目实践篇</a><ul><li><a href="/blog-test/成为ai产品经理/06.ai项目实践篇/01"><span>24 | 推荐类产品（一）：推荐系统产品经理的工作职责与必备技能</span></a></li><li><a href="/blog-test/成为ai产品经理/06.ai项目实践篇/02"><span>25 | 推荐类产品（二）：从0打造电商个性化推荐系统产品</span></a></li><li><a href="/blog-test/成为ai产品经理/06.ai项目实践篇/03"><span>26 | 预测类产品（一）：用户复购意向预测的底层逻辑是什么？</span></a></li><li><a href="/blog-test/成为ai产品经理/06.ai项目实践篇/04"><span>27 | 预测类产品（二）：从0打造一款预测用户复购意向的产品</span></a></li><li><a href="/blog-test/成为ai产品经理/06.ai项目实践篇/05"><span>28 | 预测类产品（三）：从0打造一款“大白信用评分产品”</span></a></li><li><a href="/blog-test/成为ai产品经理/06.ai项目实践篇/06"><span>29 | 自然语言处理产品：从0打造一款智能客服产品</span></a></li></ul></li><li><a href="/blog-test/成为ai产品经理/07.认知升级篇">07.认知升级篇</a><ul><li><a href="/blog-test/成为ai产品经理/07.认知升级篇/01"><span>30 | AI产品经理，你该如何提升自己的价值？</span></a></li><li><a href="/blog-test/成为ai产品经理/07.认知升级篇/02"><span>31 | AI产品经理面试，这些问题你必须会答！</span></a></li></ul></li><li><a href="/blog-test/成为ai产品经理/08.结束语">08.结束语</a><ul><li><a href="/blog-test/成为ai产品经理/08.结束语/01"><span>结束语 | 唯一不变的，就是变化本身！</span></a></li><li><a href="/blog-test/成为ai产品经理/08.结束语/02"><span>期末考试 | “AI产品经理”100分试卷等你来挑战！</span></a></li></ul></li><li><a href="/blog-test/成为ai产品经理/summary">成为ai产品经理</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="如何理解决策树？" data-depth="2"><a href="/blog-test/成为ai产品经理/04.算法技术能力篇/06#如何理解决策树"><span>如何理解决策树？</span></a></li><li title="决策树的生成" data-depth="3"><a href="/blog-test/成为ai产品经理/04.算法技术能力篇/06#决策树的生成"><span>决策树的生成</span></a></li><li title="信息熵" data-depth="3"><a href="/blog-test/成为ai产品经理/04.算法技术能力篇/06#信息熵"><span>信息熵</span></a></li><li title="剪枝操作" data-depth="3"><a href="/blog-test/成为ai产品经理/04.算法技术能力篇/06#剪枝操作"><span>剪枝操作</span></a></li><li title="决策树的应用案例：预测用户违约" data-depth="2"><a href="/blog-test/成为ai产品经理/04.算法技术能力篇/06#决策树的应用案例预测用户违约"><span>决策树的应用案例：预测用户违约</span></a></li><li title="决策树的优缺点" data-depth="2"><a href="/blog-test/成为ai产品经理/04.算法技术能力篇/06#决策树的优缺点"><span>决策树的优缺点</span></a></li><li title="随机森林：集体的力量" data-depth="2"><a href="/blog-test/成为ai产品经理/04.算法技术能力篇/06#随机森林集体的力量"><span>随机森林：集体的力量</span></a></li><li title="总结" data-depth="2"><a href="/blog-test/成为ai产品经理/04.算法技术能力篇/06#总结"><span>总结</span></a></li><li title="课后讨论" data-depth="2"><a href="/blog-test/成为ai产品经理/04.算法技术能力篇/06#课后讨论"><span>课后讨论</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="13--决策树与随机森林如何预测用户会不会违约"><a aria-hidden="true" tabindex="-1" href="/blog-test/成为ai产品经理/04.算法技术能力篇/06#13--决策树与随机森林如何预测用户会不会违约"><span class="icon icon-link"></span></a>13 | 决策树与随机森林：如何预测用户会不会违约？</h1><p>你好，我是海丰。</p><p>今天，我们要讲决策树与随机森林。决策树是一种基础的分类和回归算法，随机森林是由多棵决策树集成在一起的集成学习算法，它们都非常常用。</p><p>这节课，我就通过决策树预测用户会不会违约的例子，来给你讲讲决策树和随机森林的原理和应用。</p><h2 id="如何理解决策树"><a aria-hidden="true" tabindex="-1" href="/blog-test/成为ai产品经理/04.算法技术能力篇/06#如何理解决策树"><span class="icon icon-link"></span></a>如何理解决策树？</h2><p>很多人都有过租房子的经历，那你是怎么决定要不要租一个房子的呢？你可以先想一想，我先把我的做法说一下，我会先判断房子的位置，再看价格，最后看装修。</p><p>更具体点来说，我只会选择离公司近的房子，比如说 5 公里以内的或者通勤时间在 40 分钟以内的。其次，如果价格便宜，不管装修得好不好我都租，如果价格贵那我就要看装修情况，装修好就租，装修不好就不租。</p><p>这就是一棵典型的决策树：对于租房子这个问题，我根据距离、价格、装修这几个条件 ，对一个房子进行了判断，最后得到一个解决结果，就是这个房子我是租或者不租。下图就是这棵决策树的示意图。</p><p><img src="/images/%E6%88%90%E4%B8%BAai%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/04.%E7%AE%97%E6%B3%95%E6%8A%80%E6%9C%AF%E8%83%BD%E5%8A%9B%E7%AF%87/resourceimagee31ce358d29d64fa282b6841733b01e5421c.jpeg" alt=""/></p><p>我们可以看到，决策树（Decision Tree）就是一种树形结构的算法，上面的节点代表算法的某一个<strong>特征（如距离、价格），节点上可能存在多个分支，每一个分支代表的是这个特征的不同种类（如距离远、距离近），最后的叶子节点代表最终的决策结果（如租、不租）</strong>。</p><h3 id="决策树的生成"><a aria-hidden="true" tabindex="-1" href="/blog-test/成为ai产品经理/04.算法技术能力篇/06#决策树的生成"><span class="icon icon-link"></span></a>决策树的生成</h3><p>知道了决策树的形式和原理，我们再来看看决策树的生成过程，它是决策树的核心。不过，对于产品经理来说，更重要的还是掌握决策树的原理、形式、优缺点。那我把它的详细过程写在下面，就是让你在工作中遇到类似问题的时候，能直接回来补充必要的知识，所以今天我们先对整体过程有个大致了解就可以了。</p><p>**决策树生成的过程包括三个部分，分别是特征选择、决策树生成、决策树剪枝。**下面，我们还是拿上面租房子的例子，来说一说这个决策树生成的过程。假设现在有如下条件的一个房子，根据我上面定下的规则，你觉得这个房子我会不会租呢？</p><p><img src="/images/%E6%88%90%E4%B8%BAai%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/04.%E7%AE%97%E6%B3%95%E6%8A%80%E6%9C%AF%E8%83%BD%E5%8A%9B%E7%AF%87/resourceimage68ce684deee55d00b1942423418db7c361ce.jpeg" alt=""/></p><p>我们先看距离，因为这个房子距离公司远，所以根据上面的决策树，我们就能直接得出结论：不租。但是，假设我们的决策树不是用距离作为根节点，而是用价格作为根节点的话，结果会不会不一样呢？</p><p>这个时候，决策棵树可能会变成下面的样子：</p><p><img src="/images/%E6%88%90%E4%B8%BAai%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/04.%E7%AE%97%E6%B3%95%E6%8A%80%E6%9C%AF%E8%83%BD%E5%8A%9B%E7%AF%87/resourceimage61ab619af82a58ce588849ae5f5068043eab.jpeg" alt=""/></p><p>你会发现，我们的决策树一下子变“大”了，判断这个房子的过程就变成了，先看价格，再看装修，最后看距离。我们发现，即使决策树的结构发生了变化，可我们还是会得到之前的结论：不租，所以，决策树的构造只会影响到算法的复杂度和计算的时间，而不会影响决策的结果。</p><p>因此，在实际工作中，我们就需要优化决策树的结构，让它的效率更高，但这具体该怎么做呢？</p><h3 id="信息熵"><a aria-hidden="true" tabindex="-1" href="/blog-test/成为ai产品经理/04.算法技术能力篇/06#信息熵"><span class="icon icon-link"></span></a>信息熵</h3><p>我们一般会在特征选择和决策树的生成阶段，通过<strong>信息熵</strong>来决定哪些特征重要以及它们应该放到哪个节点上，因为信息熵是用来衡量<strong>一个节点内信息的不确定性的</strong>。一个系统中信息熵越大，这个系统的不确定性就越大，样本就越多样，你也可以理解成是样本的<strong>纯度越低</strong>，信息熵越小，系统的不确定性就越小，样本越趋于一致，那样本的<strong>纯度就越高</strong>。</p><p><img src="/images/%E6%88%90%E4%B8%BAai%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/04.%E7%AE%97%E6%B3%95%E6%8A%80%E6%9C%AF%E8%83%BD%E5%8A%9B%E7%AF%87/resourceimagee17de1c16a9cd77a60dfc08366yyb82eef7d.jpeg" alt=""/></p><p>我们肯定是希望决策树在每次划分的时候，每个条件分支都能够最大化地去划分这些样本，让每个节点的信息熵更低，样本一致性更高。所以，决策树会计算每一个特征划分后样本的“<strong>纯度</strong>”，纯度越高的特征越接近根节点。这样一来，决策树的复杂度和计算时间肯定就会越少，也就不会出现我们刚才说的那种“很大”的决策树。这就是实际工作中我们构造决策树的思路了。</p><p>实际上，决策树的算法有很多，最典型的三种分别是 ID3（Iterative Dichotomiser 3，迭代二叉树3代）、C4.5 和 CART（Classification and Regression Trees，分类与回归树）。ID3 是最初代的决策树算法，它使用的计算指标是信息增益；C4.5 是在 ID3 基础上改进后的算法，它使用的计算指标是信息增益率；CART 分类与回归树，做分类问题时使用的是 <a target="_blank" rel="noopener noreferrer" href="https://zh.wikipedia.org/wiki/%E5%9F%BA%E5%B0%BC%E7%B3%BB%E6%95%B0">Gini 系数（Gini Coefficient，基尼系数）<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>，做回归问题的时候使用的是偏差值。</p><p>作为产品经理，我们简单了解这三种算法的特点就可以了，我在下面对它们进行了总结，你可以参考一下。</p><p><img src="/images/%E6%88%90%E4%B8%BAai%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/04.%E7%AE%97%E6%B3%95%E6%8A%80%E6%9C%AF%E8%83%BD%E5%8A%9B%E7%AF%87/resourceimage84c784a031cyyd5e41232b2789b4ab41f6c7.jpeg" alt=""/></p><h3 id="剪枝操作"><a aria-hidden="true" tabindex="-1" href="/blog-test/成为ai产品经理/04.算法技术能力篇/06#剪枝操作"><span class="icon icon-link"></span></a>剪枝操作</h3><p>最后，因为决策树很容易出现过拟合情况，所以我们还会引入剪枝操作这个环节。剪枝就是我们对一棵树进行简化，减少它的复杂程度，提高模型的泛化能力。剪枝的原理很好理解，主要就是判断把某个节点去掉之后，模型的准确度会不会降低了，如果没有降低，就可以减掉这个节点。</p><p>剪枝的操作还分为预剪枝和后剪枝，它们的区别是剪枝发生的阶段不同。预剪枝在决策树生成时候同步进行。而后剪枝是决策树生成之后，再对决策树的叶子节点开始一步一步地向根方向剪枝。</p><h2 id="决策树的应用案例预测用户违约"><a aria-hidden="true" tabindex="-1" href="/blog-test/成为ai产品经理/04.算法技术能力篇/06#决策树的应用案例预测用户违约"><span class="icon icon-link"></span></a>决策树的应用案例：预测用户违约</h2><p>决策树的生成讲完了，我们重点来看看决策树的应用。在金融风控场景下，我们经常需要判断用户的违约风险。</p><p>最早的风控模型都是使用逻辑回归来做的，因为它相对简单而且可解释性强。但逻辑回归属于线性模型，不能很好处理非线性特征，所以决策树算法也慢慢用于违约风险的预测。接下来，我们就来看看决策树是怎么预测违约风险的。</p><p>决策树预测用户违约的核心思想是：<strong>先获取部分用户的历史数据，历史数据中包括过去的信贷数据和还款结果；然后将贷款客户不断进行分类，直到某个节点的样本用户都是同一个类型为止；最后，再对决策树进行剪枝，简化树的复杂度。</strong></p><p>假设我们得到的用户历史数据如下所示。对于这个表格，我再补充解释一下，过去的信贷数据应该包括申请数据、金融产品相关数据等等。年龄，是否有房这些都属于申请数据，是包括在信贷数据里的。</p><p>还款结果指的是什么时候还款，还了多少，但是做模型设计，定义模型目标变量的时候，我们不可能直接用还款数据，所以我们定义是否逾期作为目标值，也就是 Y 值。1 代表逾期，0 代表不逾期。</p><p><img src="/images/%E6%88%90%E4%B8%BAai%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/04.%E7%AE%97%E6%B3%95%E6%8A%80%E6%9C%AF%E8%83%BD%E5%8A%9B%E7%AF%87/resourceimagea349a3d903270195ca1984452862a7e20849.jpeg" alt=""/></p><p>因为目前决策树算法中，使用比较多的是 CART 算法，所以我们也选择它进行模型构建，而特征选择阶段会使用 Gini 系数。 CART 算法选择 Gini 系数，是因为信息熵模型使用了大量的对数计算导致效率很低，而 Gini 系统可以避免这个问题，从而提升计算效率。</p><p>从上面的历史数据中，我们可以提取出三个特征，分别是性别、年龄和是否有房。接下来，我们就分别计算一下这三个特征的 Gini 系数。</p><p>首先，性别特征的 Gini 系数直接根据公式计算就可以了，我们假设它就是 0.412。</p><p><img src="/images/%E6%88%90%E4%B8%BAai%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/04.%E7%AE%97%E6%B3%95%E6%8A%80%E6%9C%AF%E8%83%BD%E5%8A%9B%E7%AF%87/resourceimage3ecd3e00a6868442cb4aa76ca685eb0d52cd.jpeg" alt=""/></p><p>我们重点来看第二个特征：年龄。年龄是一个连续的值，我们的历史数据中一共有 4 种数值，每两个相邻值之间都可以是一个特征分类的点（比如说，年龄 22 和年龄 24 的分类点就是23），所以对于年龄这个特征，我们一共有3种不同的分类方式。因为分类方式比较多，相对应的，Gini 的计算方式就会比较复杂，我们需要分别计算3种不同分类方式时的 Gini 系数，选出 Gini 最小的分类方式，把它作为年龄的分类。</p><p>假设年龄在 37 的时候 Gini 系数最小，等于 0.511，那么年龄这个特征的条件分支就是小于 37 和大于 37。</p><p>相同的，我们可以再计算是否有房的 Gini 系数。假设这个特征的 Gini 系数为 0.113，最后，根据 Gini 排序我们就能得到如下的决策树结构。</p><p><img src="/images/%E6%88%90%E4%B8%BAai%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/04.%E7%AE%97%E6%B3%95%E6%8A%80%E6%9C%AF%E8%83%BD%E5%8A%9B%E7%AF%87/resourceimage677467169bb3yy9e13dc29f86490b67af374.jpeg" alt=""/></p><p>但是，这个决策树还不是最终的结构，因为有些节点我们是可以去掉的。比如说，我们发现有房产这个条件下面的所有节点，去掉和不去掉的时候模型准确性没有变化，那我们就可以把有房产下面的所有节点裁剪掉，从而得到新的决策树。</p><p>这就是剪枝操作，在我们实际工作中通常采取后剪枝的操作，从叶子节点逐步向上判断哪些节点是可以去掉的，剪枝后的决策树如下所示。</p><p><img src="/images/%E6%88%90%E4%B8%BAai%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/04.%E7%AE%97%E6%B3%95%E6%8A%80%E6%9C%AF%E8%83%BD%E5%8A%9B%E7%AF%87/resourceimage036703b29d852885211dd2d5bc567934c867.jpeg" alt=""/></p><p>以上就是决策树创建的过程，因为没有进行实际计算，实际结果可能有偏差，你只要理解这个过程就可以了。</p><h2 id="决策树的优缺点"><a aria-hidden="true" tabindex="-1" href="/blog-test/成为ai产品经理/04.算法技术能力篇/06#决策树的优缺点"><span class="icon icon-link"></span></a>决策树的优缺点</h2><p>通过上面的学习我们可以发现，决策树的优点和缺点都很明显。由于具有树形结构所以决策树的可解释性强，直观好理解，而且我们还可以从结果向上去追溯原因。采用决策树，我们可以很方便地和领导、业务方、甲方去解释我们的模型是什么，以及有哪些因素影响了模型的结果。</p><p>不过，决策树的缺点也非常明显。当数据量大，数据维度（样本具有的特征或者属性，如价格、位置）很多的时候，决策树会变得非常复杂，训练时间会很久。</p><p>另外，决策树还有一个很明显的缺点就是，需要算法同学手工设置决策树的深度（决策树要分多少层），如果设置了不合适的参数，就很可能造成欠拟合或者过拟合的情况。比如说，深度太浅就意味着你的叶子节点分得不干净，很容易造成欠拟合的情况，深度太深也会导致决策树训练时间太久，复杂度太高，很容易造成过拟合的情况。</p><h2 id="随机森林集体的力量"><a aria-hidden="true" tabindex="-1" href="/blog-test/成为ai产品经理/04.算法技术能力篇/06#随机森林集体的力量"><span class="icon icon-link"></span></a>随机森林：集体的力量</h2><p>在实际工作中，我们既可以只使用一棵决策树来解决问题，也可以使用多棵决策树来共同解决问题，也就是随机森林。</p><p>随机森林（Random Forest）指的是由多棵决策树组成，随机指的是每一个决策树的样本是随机从数据集中采样得到的。假设， 模型由三个决策树A、B、C组成，我们给每棵决策树都随机抽取样本进行训练，由于这三棵树的训练样本不一样，因此它们最后得到的决策结果有可能不同。最后，我们再把这三棵树得到的结果做一个综合，就能得到最终的决策结果了。</p><p>随机森林的原理很好理解，那我们再来说说它的优缺点。因为这个算法是随机从数据集中进行采样的，所以模型的随机性很强，不容易产生过拟合的情况，但正因为样本是随机的，所以模型对于样本数据的异常值也不太敏感。</p><p>其次，因为算法采样的时候，是从整个数据集中抽取其中一部分进行采样，而且随机森林是由多棵树组合而成的，所以模型中的每一棵决策树都可以并行训练和计算，这样一来，在面向大数据量的情况下，随机森林的运行效率更高。</p><p>也正是因为这样，随机森林在训练时候需要的计算成本会更高，而且，就算它们整合之后会比之前单一模型表现好，但在面对复杂样本的时候，它们仍然没有办法很好区分，所以模型上限很低。</p><p>随机森林属于集成学习中的一种。集成学习（Ensemble Learning）可以理解为，不是通过某一个单独的机器学习算法解决问题，而是通过多个机器学习算法结合使用来完成最终的算法，最终达到 1+1&gt;2 的效果。核心原理你可以记成是我们常说的“三个臭皮匠赛过一个诸葛亮”。</p><p>集成学习的内部由很多<a target="_blank" rel="noopener noreferrer" href="https://www.cnblogs.com/yumoye/p/11025504.html">弱监督模型<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>组成， 某一个弱监督模型只在某一个方向上表现比较好，当我们把这些算法合而为一的时候，就会得到一个各方面都会表现较好的模型。集成学习的算法有很多，随机森林是其中比较有代表性的一种。我在下面整理了一个集成学习的思维导图，你可以了解一下。</p><p><img src="/images/%E6%88%90%E4%B8%BAai%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/04.%E7%AE%97%E6%B3%95%E6%8A%80%E6%9C%AF%E8%83%BD%E5%8A%9B%E7%AF%87/resourceimage50bd50d6fe5acc9a759798cba086926981bd.jpg" alt=""/></p><h2 id="总结"><a aria-hidden="true" tabindex="-1" href="/blog-test/成为ai产品经理/04.算法技术能力篇/06#总结"><span class="icon icon-link"></span></a>总结</h2><p>今天，我们讲了决策树、随机森林的原理、应用和优缺点。理解决策树是理解随机森林和集成学习的基础，不过，作为产品经理，我们的重点不在于理解决策树的生成过程，只是借着它的生成加深对决策树原理和应用的理解。</p><p>总的来说，关于决策树和随机森林，我希望你重点记住这 5 点：</p><ol><li><p>决策树就是一种树形结构的算法，它很直观，可视化很强，但也容易过拟合；</p></li><li><p>决策树特征选择是生成决策树的基础，不同的算法对应了不同的特征选择方式；</p></li><li><p>集成学习是多个机器学习算法的结合；</p></li><li><p>随机森林是集成学习中的一种，由多棵决策树组成；</p></li><li><p>随机森林的原理你可以记成：三个臭皮匠赛过一个诸葛亮，它的特点你可以记成：模型起点高、天花板低。</p></li></ol><p>除此之外，关于决策树和随机森林的应用场景我还想再强调一下。决策树和随机森林模型的可解释度都很高，这就意味着我们可以轻松地把模型的计算逻辑介绍清楚。</p><p>实际上，这一点对于咨询、金融、医疗领域的公司来说非常重要，因为你的客户往往不懂你的模型内部在做什么，但如果你的模型结构清晰，你就能在最短的时间内介绍出模型的优势。而且，因为随机森林这样的集成学习算法融合了多个模型的优点，所以对于解决分类问题来说，决策树和随机森林是当今的机器学习算法的首选，就比如你可能听过的 GBDT、XGBoost 就是决策树的升级版。</p><h2 id="课后讨论"><a aria-hidden="true" tabindex="-1" href="/blog-test/成为ai产品经理/04.算法技术能力篇/06#课后讨论"><span class="icon icon-link"></span></a>课后讨论</h2><p>因为产品经理不需要实际进行模型的构建，所以我不会让你去构建一棵决策树，我想请你来梳理一下，你所在的团队中有哪些项目是基于决策树、随机森林或者是升级算法解决的呢？</p><p>欢迎在留言区分享你的经验，我们下节课见！</p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/ssrc/成为ai产品经理/04.算法技术能力篇/06.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/23 16:17:58</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-test/umi.js"></script>
  </body>
</html>
